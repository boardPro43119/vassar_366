My first step was to write the resnik_similarity() function to compute similarity of pairs of words (w1, w2). I accomplished this with a triple-nested for loop. The outside loop iterates over w1's senses and the middle loop iterates over w2's senses. The inside loop calls and iterates over the common_hypernyms() of senses s1 and s2 of w1 and w2 respectively. In each execution of the for loop, I use the information_content() function to compute the similarity score. The function returns a list consisting of the sense of w1 with the highest similarity score to a sense of w2, and the similarity score for this sense.

At that point, I was confused, because I thought my function should compare pairs of probe words and individual context words. I was especially concerned that I was getting below 50% accuracy when running my program, and that certain guesses made very little sense. For example, the pair for the pair (head, body) the sense was guessed as head.30, meaning "a toilet on board a ship." After looking closely at the Resnik article, I realized that I had in fact only implemented what the wsim() function, and that the task was in fact to treat entire lines of context words as context when looking at each one individually.

From there, I proceeded to build an additional section of code that followed the same general structure as the version provided in the article. It took me a relatively short amount of time to notice the way in which the assignment question was simpler than the full algorithm: we only had to treat the first word on each line as a probe word, rather than each word in sequence. This meant that I was able to use just one inner for loop in the top outer loop, make the second outer loop a single for loop rather than a nested one, and represent support and normalization as a one-dimensional array and a single value respectively (rather than 2D and 1D arrays).

The most difficult part of implementing my additional code was figuring out how to check whether the most informative subsumer was an ancestor of each probe sense (probe_senses{k]). I first tried calling the hypernyms() function on probe_senses[k], but diagnostic printouts of the phi-values yielded all zeroes. Through researching the documentation, I found the desired property to be probe_senses[k]._all_hypernyms. (It turns out that the hypernyms() function only returns the hypernyms one level above the current sense.)

After I changed this, there was one more small problem, which occurred because the word "hotline" was not found in the WordNet dictionary, so attempting to refer to its senses caused an error. I fixed this by refining the limits of my for loops and adding a check to make sure c was not null before attempting to see if it was in the list of hypernyms.

My code now produces reasonable phi-values for all the comparisons, and achieves just above 50% accuracy, with 10 out of 18 correctly guessed senses for probe words.
